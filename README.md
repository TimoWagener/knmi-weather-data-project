# KNMI Weather Data Lakehouse ğŸŒ¦ï¸

A production-ready data lakehouse for Dutch weather data using **medallion architecture** (Bronze/Silver/Gold layers) with **93.5% API optimization** through multi-station batch loading.

Downloads hourly weather observations from the KNMI EDR API, processes through data quality layers, and provides efficient querying with DuckDB, Polars, and Pandas.

![Data Architecture](https://img.shields.io/badge/Architecture-Medallion-blue)
![Python](https://img.shields.io/badge/Python-3.10%2B-green)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Optimization](https://img.shields.io/badge/API_Efficiency-93.5%25-brightgreen)

## ğŸŒŸ Features

- ğŸš€ **93.5% API Optimization**: Multi-station batch loading (v2) - load 8 stations with 156 API calls vs 2,400!
- âœ… **Medallion Architecture**: Bronze (raw) â†’ Silver (validated) â†’ Gold (aggregated)
- âœ… **Modern Stack**: DuckDB, Polars, Pandas, Parquet, Python 3.10+
- âœ… **Data Quality**: Automated validation, outlier detection, quality scoring
- âœ… **Efficient Storage**: Columnar Parquet with monthly partitioning
- âœ… **Fast Queries**: Sub-second queries on millions of records
- âœ… **77 Stations Available**: Access to all KNMI weather stations across Netherlands
- âœ… **Scalable**: Can load 48-60 stations per session (entire KNMI network in 2-3 hours!)
- âœ… **Metadata Tracking**: Automated load status, gap detection, resume capability
- âœ… **Secure**: API keys in .env, not in code

## ğŸ“Š Current Data

- **Stations Loaded**: All 10 core stations are fully loaded
  - âœ… Hupsel, Deelen, De Bilt, Schiphol, Rotterdam, Vlissingen, Maastricht, Eelde, Den Helder, Twenthe
- **Coverage**: 1990-2025 (36 years per station = 360 station-years)
- **Parameters**: 23+ weather measurements (temp, humidity, rainfall, wind, etc.)
- **Bronze Raw**: ~1.3 GB JSON (360 station-years) âœ… COMPLETE
- **Bronze Refined**: ~200 MB Parquet with monthly partitioning âœ… COMPLETE
- **Next Phase**: Silver layer (validation, cleaning, quality scoring)

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
git clone <repository-url>
cd LocalWeatherDataProject

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Keys

```bash
# Copy template
cp .env.example .env

# Edit .env and add your KNMI API keys
# Get keys from: https://developer.dataplatform.knmi.nl/
```

### 3. Download and Transform Data

```bash
# ğŸš€ STEP 1: Ingest Bronze Raw data (JSON from API)
# This command is idempotent and will skip already downloaded years
python -m data_orchestration.bronze_raw.orchestrate --stations core_10 --start-year 1990 --end-year 2025

# ğŸš€ STEP 2: Transform to Bronze Refined (Parquet with monthly partitioning)
# This command is idempotent and will skip already transformed months
python -m data_orchestration.bronze_refined.orchestrate --stations core_10 --start-year 1990 --end-year 2025

# ğŸ“Š STEP 3: Transform to Silver layer (validation, quality scoring)
# Coming soon - currently in development
# python -m data_orchestration.silver.orchestrate --stations core_10 --start-year 1990 --end-year 2025
```

### 4. Query the Data

```bash
# Run demo queries
python src/query_demo.py
```

## ğŸ“ Project Structure

```
LocalWeatherDataProject/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ GEMINI.md             # Current project status and next steps
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env.example         # API key template
â”œâ”€â”€ .gitignore           # Git ignore rules
â”‚
â”œâ”€â”€ data_orchestration/  # CORE: Bronze ingestion orchestrator
â”‚   â””â”€â”€ bronze_raw/
â”‚       â”œâ”€â”€ orchestrate.py
â”‚       â”œâ”€â”€ station_pipeline.py
â”‚       â”œâ”€â”€ api_client.py
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/                 # CORE: Transformation logic
â”‚   â”œâ”€â”€ config.py                       # Global configuration
â”‚   â”œâ”€â”€ transform_bronze_refined.py     # JSON â†’ Parquet
â”‚   â”œâ”€â”€ transform_silver.py             # Parquet â†’ Validated Parquet
â”‚   â””â”€â”€ query_demo.py                   # Demo queries (DuckDB/Polars/Pandas)
â”‚
â”œâ”€â”€ archive/
â”‚   â”œâ”€â”€ legacy_v2/                      # Old v2 multi-station batching scripts
â”‚   â”œâ”€â”€ outdated_docs/                  # Old project status and research docs
â”‚   â””â”€â”€ v1_single_station/              # Original single-station scripts
â”‚
â”œâ”€â”€ docs/                # Project documentation
â”‚   â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ research/
â”‚   â””â”€â”€ ingestion_strategy/
â”‚
â”œâ”€â”€ metadata/            # Orchestration metadata
â”‚   â”œâ”€â”€ stations_config.json
â”‚   â””â”€â”€ bronze_raw/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ logs/                # .log and .json structured logs
â”‚
â”œâ”€â”€ data/                # Data files (not in git)
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ raw/        # Immutable JSON from API
â”‚   â”‚   â””â”€â”€ refined/    # Queryable Parquet
â”‚   â”œâ”€â”€ silver/         # Validated & cleaned
â”‚   â””â”€â”€ gold/           # Aggregated (not yet built)
â”‚
â””â”€â”€ ...
```

## ğŸ—ï¸ Architecture

### Medallion Layers

**Bronze Raw** (Immutable Source of Truth) âœ…
- Format: JSON (exact EDR API responses)
- Purpose: Compliance, reprocessing, debugging
- Size: ~1.3 GB for 360 station-years
- Status: PRODUCTION-READY

**Bronze Refined** (Schema-on-Read) âœ…
- Format: Parquet (columnar, compressed, monthly partitioned)
- Schema: Dynamic (preserves all source fields)
- Compression: ~11x (3.76 MB JSON â†’ ~330 KB Parquet per year)
- Size: ~200 MB for full dataset
- Status: PRODUCTION-READY

**Silver** (Validated & Cleaned) ğŸš§
- Format: Parquet with fixed schema
- Features: Quality scoring, outlier detection, deduplication
- Status: IN DEVELOPMENT

**Gold** (Business Intelligence) ğŸ“‹
- Purpose: Aggregated metrics, multi-station comparisons
- Future: Daily summaries, station comparisons, dashboards

### Data Flow

```
KNMI EDR API
    â†“ (Monthly chunks)
Bronze Raw (JSON)
    â†“ (Flatten structure)
Bronze Refined (Parquet, schema-on-read)
    â†“ (Validate, clean, score quality)
Silver (Parquet, fixed schema)
    â†“ (Aggregate, model)
Gold (Business-ready)
```





## ğŸ”§ Configuration

Edit `src/config.py` to customize:

- **Stations**: Add more weather stations
- **Date Ranges**: Define custom time periods
- **Parameters**: Select specific weather variables
- **Paths**: Change data storage locations

## ğŸ“š Documentation

- **[GEMINI.md](GEMINI.md)**: Current project status, next steps, and core principles.
- **[Architecture Docs](docs/architecture/)**: High-level design documents, including the overall Medallion plan and v3 orchestration design.
- **[Research Docs](docs/research/)**: Deep dives into API optimization and comparisons.
- **[Ingestion Strategy](docs/ingestion_strategy/)**: Detailed plans and findings related to the Bronze ingestion process.

## ğŸ¤ Contributing

This is a personal project, but feel free to fork and adapt for your own use!

## ğŸ“ License

MIT License - feel free to use and modify

## ğŸ™ Acknowledgments

- **KNMI** (Royal Netherlands Meteorological Institute) for providing free weather data
- **EDR API** following OGC Environmental Data Retrieval standards
- Built with **DuckDB**, **Parquet**, and **Python**




